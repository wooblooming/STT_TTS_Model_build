{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33152,"status":"ok","timestamp":1710829676144,"user":{"displayName":"이채원","userId":"02545855121528690953"},"user_tz":-540},"id":"X6QlO8uFvwWm","outputId":"199c8500-ac26-4899-e36b-57d3d2a442a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n","Collecting SpeechRecognition\n","  Downloading SpeechRecognition-3.10.1-py2.py3-none-any.whl (32.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.31.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n","Installing collected packages: SpeechRecognition\n","Successfully installed SpeechRecognition-3.10.1\n","Obtaining file:///content\n","\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install pydub\n","!pip install SpeechRecognition\n","!pip install -e ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PD9pBs7ev-Yx"},"outputs":[],"source":["from pydub import AudioSegment\n","from pydub.silence import detect_silence\n","from pydub.silence import detect_nonsilent\n","from keras.models import load_model\n","\n","import numpy as np\n","import os\n","import librosa\n","import sklearn\n","import speech_recognition as sr\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23967,"status":"ok","timestamp":1710829706141,"user":{"displayName":"이채원","userId":"02545855121528690953"},"user_tz":-540},"id":"WrfTmm39wBT9","outputId":"31078bf4-506e-499e-cdb7-3837eb792cd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0MhBOshwCc1"},"outputs":[],"source":["# '음','그','어'등의 비언어적 표현 구분 모델\n","filler_determine_model = load_model('/content/drive/MyDrive/leanai/ML/STT/model/filler_classifier_by_train2_1215.h5')\n","# 비언어적 표현을 판별하는 모델\n","filler_classifier_model = load_model('/content/drive/MyDrive/leanai/ML/STT/model/filler_determine_model_by_train2_1205.h5')\n","\n","# filler_classifier_model = load_model('/content/drive/MyDrive/leanai/ML/STT/model/filler_classifier_by_train2_1215.h5')\n","# filler_determine_model = load_model('/content/drive/MyDrive/leanai/ML/STT/model/filler_determine_model_by_train2_1205.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NMs0AbDzwVP5"},"outputs":[],"source":["pad1d = lambda a, i: a[0: i] if a.shape[0] > i else np.hstack((a, np.zeros(i-a.shape[0])))\n","pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n","\n","frame_length = 0.025\n","frame_stride = 0.0010"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XMEmmT90H4-K"},"outputs":[],"source":["#adjust target amplitude\n","def match_target_amplitude(sound, target_dBFS):\n","    change_in_dBFS = target_dBFS - sound.dBFS\n","    return sound.apply_gain(change_in_dBFS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5-Xjt_Kwh01"},"outputs":[],"source":["# 오디오 파일에서 비언어적 표현을 식별하는 함수\n","\n","def predict_filler(audio_file):\n","  # 추임새 판별을 위한 임시 음성 파일 생성\n","  audio_file.export(\"temp.wav\", format=\"wav\")\n","\n","  wav, sr = librosa.load(\"temp.wav\", sr=16000)\n","\n","  mfcc = librosa.feature.mfcc(y=wav)\n","  padded_mfcc = pad2d(mfcc, 40)\n","  padded_mfcc = np.expand_dims(padded_mfcc, 0)\n","\n","  result = filler_classifier_model.predict(padded_mfcc)\n","\n","  # 판별 완료된 음성 파일 삭제\n","  os.remove(\"temp.wav\")\n","\n","  if result[0][0] >= result[0][1]: # 추임새\n","    return 0\n","  else:\n","    return 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QK9xFxBZxPSw"},"outputs":[],"source":["# 비언어적 표현의 종류를 분류하는 함수\n","\n","def predict_filler_type(audio_file):\n","  # 추임새 종류 판별을 위한 임시 음성 파일 생성\n","  audio_file.export(\"temp.wav\", format=\"wav\")\n","\n","  wav, sr = librosa.load(\"temp.wav\", sr=16000)\n","  input_nfft = int(round(sr*frame_length))\n","  input_stride = int(round(sr*frame_stride))\n","\n","  mfcc = librosa.feature.mfcc(y=wav)\n","  padded_mfcc = pad2d(mfcc, 40)\n","  padded_mfcc = np.expand_dims(padded_mfcc, 0)\n","\n","  result = filler_classifier_model.predict(padded_mfcc)\n","\n","  # 판별 완료된 음성 파일 삭제\n","  os.remove(\"temp.wav\")\n","\n","  return np.argmax(result)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1DEHThTR6Ad1"},"outputs":[],"source":["def shorter_filler(json_result, audio_file, min_silence_len, start_time, non_silence_start):\n","\n","  # 침묵 길이를 더 짧게\n","  min_silence_length = (int)(min_silence_len/1.2)\n","\n","  intervals = detect_nonsilent(audio_file,\n","                              min_silence_len=min_silence_length,\n","                              silence_thresh=-32.64\n","                              )\n","\n","  for interval in intervals:\n","\n","    interval_audio = audio_file[interval[0]:interval[1]]\n","\n","    # padding 40 길이 이상인 경우 더 짧게\n","    if (interval[1]-interval[0] >= 460):\n","      non_silence_start = shorter_filler(json_result, interval_audio, min_silence_length, interval[0]+start_time, non_silence_start)\n","\n","    else: # padding 40 길이보다 짧은 경우 predict\n","      if predict_filler(interval_audio) == 0 : # 추임새인 경우\n","        json_result.append({'start':non_silence_start,'end':start_time+interval[0],'tag':'1000'}) # tag: 1000 means non-slience\n","        non_silence_start = start_time + interval[0]\n","\n","        # 추임새 tagging\n","        json_result.append({'start':start_time+interval[0],'end':start_time+interval[1],'tag':'1111'}) # tag: 1111 means filler word\n","\n","\n","  return non_silence_start"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9d9URQmDxedV"},"outputs":[],"source":["def create_json(audio_file):\n","  intervals_jsons = []\n","\n","  min_silence_length = 70\n","  intervals = detect_nonsilent(audio_file,\n","                              min_silence_len=min_silence_length,\n","                              silence_thresh=-32.64\n","                              )\n","\n","  if intervals[0][0] != 0:\n","    intervals_jsons.append({'start':0,'end':intervals[0][0],'tag':'0000'}) # tag: 0000 means silence\n","\n","  non_silence_start = intervals[0][0]\n","  before_silence_start = intervals[0][1]\n","\n","  for interval in intervals:\n","    interval_audio = audio_file[interval[0]:interval[1]]\n","\n","     # 800ms초 이상의 공백 부분 처리\n","    if (interval[0]-before_silence_start) >= 800:\n","      intervals_jsons.append({'start':non_silence_start,'end':before_silence_start+200,'tag':'1000'}) # tag: 1000 means non-slience\n","      non_silence_start = interval[0]-200\n","      intervals_jsons.append({'start':before_silence_start,'end':interval[0],'tag':'0000'}) # tag: 0000 means slience\n","\n","    if predict_filler(interval_audio) == 0 : # 추임새인 경우\n","      if len(interval_audio) <= 460:\n","        intervals_jsons.append({'start':non_silence_start,'end':interval[0],'tag':'1000'}) # tag: 1000 means non-slience\n","        non_silence_start = interval[0]\n","        intervals_jsons.append({'start':interval[0],'end':interval[1],'tag':'1111'})\n","      else:\n","        non_silence_start = shorter_filler(intervals_jsons, interval_audio, min_silence_length, interval[0], non_silence_start)\n","\n","    before_silence_start = interval[1]\n","\n","  if non_silence_start != len(audio_file):\n","    intervals_jsons.append({'start':non_silence_start,'end':len(audio_file),'tag':'1000'})\n","\n","  return intervals_jsons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-76aios1CVl"},"outputs":[],"source":["def STT_with_json(audio_file, jsons):\n","  first_silence = 0\n","  num = 0\n","  unrecognizable_start = 0\n","  r = sr.Recognizer()\n","  transcript_json = []\n","  statistics_filler_json = []\n","  statistics_silence_json = []\n","  filler_1 = 0\n","  filler_2 = 0\n","  filler_3 = 0\n","  audio_total_length = audio_file.duration_seconds\n","  silence_interval = 0\n","  for json in jsons :\n","    if json['tag'] == '0000':\n","      # 통역 개시 지연시간\n","      if num == 0:\n","        first_silence = first_silence + (json['end']-json['start'])/1000\n","      else:\n","        silence_interval = silence_interval + (json['end']-json['start'])/1000\n","        silence = \"(\" + str(round((json['end']-json['start'])/1000)) + \"초)..\"\n","        transcript_json.append({'start':json['start'],'end':json['end'],'tag':'0000','result':silence})\n","\n","    elif json['tag'] == '1111':\n","      # 통역 개시 지연시간\n","      if num == 0:\n","        silence = \"(\" + str(round(first_silence)) + \"초)..\"\n","        transcript_json.append({'start':0,'end':json['start'],'tag':'0000','result':silence})\n","        first_silence_interval = first_silence\n","      # 추임새(어, 음, 그) 구분\n","      filler_type = predict_filler_type(audio_file[json['start']:json['end']])\n","      if filler_type == 0 :\n","        transcript_json.append({'start':json['start'],'end':json['end'],'tag':'1001','result':'어(추임새)'})\n","        filler_1 = filler_1 + 1\n","      elif filler_type == 1:\n","        transcript_json.append({'start':json['start'],'end':json['end'],'tag':'1010','result':'음(추임새)'})\n","        filler_2 = filler_2 + 1\n","      else:\n","        transcript_json.append({'start':json['start'],'end':json['end'],'tag':'1100','result':'그(추임새)'})\n","        filler_3 = filler_3 + 1\n","      num = num + 1\n","\n","    elif json['tag'] == '1000':\n","\n","      # 인식불가 처리\n","      if unrecognizable_start != 0:\n","        audio_file[unrecognizable_start:json['end']].export(\"temp.wav\", format=\"wav\")\n","      else:\n","        audio_file[json['start']:json['end']].export(\"temp.wav\", format=\"wav\")\n","      temp_audio_file = sr.AudioFile('temp.wav')\n","      with temp_audio_file as source:\n","        audio = r.record(source)\n","      try :\n","        stt = r.recognize_google(audio_data = audio, language = \"ko-KR\")\n","        # 통역 개시 지연시간\n","        if num == 0:\n","          silence = \"(\" + str(round(first_silence)) + \"초)..\"\n","          transcript_json.append({'start':0,'end':json['start'],'tag':'0000','result':silence})\n","          first_silence_interval = first_silence\n","        if unrecognizable_start != 0:\n","          transcript_json.append({'start':unrecognizable_start,'end':json['end'],'tag':'1000','result':stt})\n","        else:\n","          transcript_json.append({'start':json['start'],'end':json['end'],'tag':'1000','result':stt})\n","        unrecognizable_start = 0\n","        num = num + 1\n","      except:\n","        if unrecognizable_start == 0:\n","          unrecognizable_start = json['start']\n","\n","  statistics_filler_json.append({'어':filler_1, '음':filler_2, '그':filler_3})\n","  statistics_silence_json.append({'발화지연시간':100 * first_silence_interval/audio_total_length, '침묵시간':100 * silence_interval/audio_total_length, '발화시간':100 * (audio_total_length - first_silence - silence_interval)/audio_total_length})\n","  return transcript_json, statistics_filler_json, statistics_silence_json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiE6rc3u59Os"},"outputs":[],"source":["def make_transcript(audio_file_path):\n","  audio = AudioSegment.from_mp3(audio_file_path)\n","  normalized_audio = match_target_amplitude(audio, -20.0)\n","  intervals_jsons = create_json(normalized_audio)\n","  transcript_json = STT_with_json(normalized_audio, intervals_jsons)\n","\n","  return transcript_json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46948,"status":"ok","timestamp":1710829756137,"user":{"displayName":"이채원","userId":"02545855121528690953"},"user_tz":-540},"id":"8b7343H5A3W_","outputId":"c4a55a2f-75f3-40f8-a949-967af895e8bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 207ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=272\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=128\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=48\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=64\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=112\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 34ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1712\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1888\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=176\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=16\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 34ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=96\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=240\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 36ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=192\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 37ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1536\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=160\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=80\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1424\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 35ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1728\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 63ms/step\n","1/1 [==============================] - 0s 36ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=32\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 52ms/step\n","1/1 [==============================] - 0s 43ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 38ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=640\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=960\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=144\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 38ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1072\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=304\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1360\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1200\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1920\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 56ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=560\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1296\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=1696\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 33ms/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/librosa/core/spectrum.py:257: UserWarning: n_fft=2048 is too large for input signal of length=320\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 38ms/step\n"]}],"source":["transcript_json, statistics_filler_json, statistics_silence_json = make_transcript(\"/content/drive/MyDrive/leanai/ML/STT/sample/stt_test.wav\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1710829756137,"user":{"displayName":"이채원","userId":"02545855121528690953"},"user_tz":-540},"id":"cOGloHR_Gi6R","outputId":"6e4ab502-a490-430b-b6fb-cb129f168fa1"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'start': 0, 'end': 1270, 'tag': '0000', 'result': '(1초)..'}\n","{'start': 1270, 'end': 7874, 'tag': '1000', 'result': '라운드 로빈의 CPU 스케줄링 알고리즘으로 프로듀스의 동일한 시간을 할당하고'}\n","{'start': 7674, 'end': 8784, 'tag': '0000', 'result': '(1초)..'}\n","{'start': 8584, 'end': 13425, 'tag': '1000', 'result': '사용하여 공평하게 CPU 시간을 나눠 줍니다'}\n","{'start': 13225, 'end': 14534, 'tag': '0000', 'result': '(1초)..'}\n","{'start': 14534, 'end': 14919, 'tag': '1001', 'result': '어(추임새)'}\n","{'start': 14334, 'end': 22280, 'tag': '1000', 'result': '시간 할당량이 크면 문맥 교환이 빈번하게 일어나 성능이 저하될 수 있고 작으면'}\n","{'start': 22280, 'end': 22281, 'tag': '1001', 'result': '어(추임새)'}\n","{'start': 22282, 'end': 22283, 'tag': '1001', 'result': '어(추임새)'}\n","{'start': 22280, 'end': 23787, 'tag': '1000', 'result': '시간이 길어질 수 있습니다'}\n","{'start': 23787, 'end': 23807, 'tag': '1001', 'result': '어(추임새)'}\n"]}],"source":["for transcript in transcript_json:\n","  print(transcript)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710829756137,"user":{"displayName":"이채원","userId":"02545855121528690953"},"user_tz":-540},"id":"x388PYt6GvJB","outputId":"7e386489-f0e3-44c4-b4ee-be5677de75f9"},"outputs":[{"data":{"text/plain":["[{'어': 4, '음': 0, '그': 0}]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["statistics_filler_json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1710829756438,"user":{"displayName":"이채원","userId":"02545855121528690953"},"user_tz":-540},"id":"fLhqPUOvVEos","outputId":"23177779-aa4d-469f-b728-446c1e244de2"},"outputs":[{"data":{"text/plain":["[{'발화지연시간': 5.132004310344827,\n","  '침묵시간': 9.775053879310345,\n","  '발화시간': 85.09294181034483}]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["statistics_silence_json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1710829756438,"user":{"displayName":"이채원","userId":"02545855121528690953"},"user_tz":-540},"id":"tnZ63DWFFXYx","outputId":"d9120014-132c-4de4-8ef2-67eb6b2ef3cc"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'라운드 로빈의 CPU 스케줄링 알고리즘으로 프로듀스의 동일한 시간을 할당하고 사용하여 공평하게 CPU 시간을 나눠 줍니다 시간 할당량이 크면 문맥 교환이 빈번하게 일어나 성능이 저하될 수 있고 작으면 시간이 길어질 수 있습니다'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["answer = [item['result'] for item in transcript_json]\n","filtered_answer = [value for value in answer if ('(추임새)' not in value) and ('..' not in value)]\n","\n","filtered_answer = ' '.join(filtered_answer)\n","filtered_answer"]},{"cell_type":"markdown","metadata":{"id":"hEGJ2iOIFlfx"},"source":["### Whipser 이용 STT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":179546,"status":"ok","timestamp":1711089986534,"user":{"displayName":"이채원","userId":"02545855121528690953"},"user_tz":-540},"id":"pMPEz5v5v6QU","outputId":"9ab5a0df-2db2-4968-cb4b-70807baf8214"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ckug6q7s\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ckug6q7s\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n","Collecting tiktoken (from openai-whisper==20231117)\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=77e6b674435c39f2493a1d2e6e72ecf4e74a4c8007d8b59d8ec71cef31bfa7ea\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-pcxwtzfv/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n","Successfully built openai-whisper\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.6.0\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-txa_t92h\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-txa_t92h\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.1+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.2)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.6.0)\n","Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.4.99)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n","Collecting git+https://github.com/openai/whisper.git\n","  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-2z9oem39\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-2z9oem39\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=b315727fd30c75e08ac8f4c29bcc971b53c704a5f3ab1968d9a7a2cb1afa5bc4\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-42xksbiz/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n","Successfully built openai-whisper\n","Installing collected packages: openai-whisper\n","  Attempting uninstall: openai-whisper\n","    Found existing installation: openai-whisper 20231117\n","    Uninstalling openai-whisper-20231117:\n","      Successfully uninstalled openai-whisper-20231117\n","Successfully installed openai-whisper-20231117\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n","Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,898 kB]\n","Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,356 kB]\n","Fetched 3,487 kB in 2s (2,013 kB/s)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","39 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"]}],"source":["!pip install git+https://github.com/openai/whisper.git\n","!pip install git+https://github.com/openai/whisper.git\n","!pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git\n","!sudo apt update && sudo apt install ffmpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YEI1beXiwbju","executionInfo":{"status":"ok","timestamp":1711090069445,"user_tz":-540,"elapsed":82917,"user":{"displayName":"이채원","userId":"02545855121528690953"}},"outputId":"a5363122-7f92-4d8d-a956-406f644dea8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["100%|██████████████████████████████████████| 2.88G/2.88G [00:29<00:00, 104MiB/s]\n","/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n","  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 58, in load_audio\n","    out = run(cmd, capture_output=True, check=True).stdout\n","  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n","    raise CalledProcessError(retcode, process.args,\n","subprocess.CalledProcessError: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', '/content/drive/MyDrive/졸프/ML/STT/sample/stt_test.wav', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 1.\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 597, in cli\n","    result = transcribe(model, audio_path, temperature=temperature, **args)\n","  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 133, in transcribe\n","    mel = log_mel_spectrogram(audio, model.dims.n_mels, padding=N_SAMPLES)\n","  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 140, in log_mel_spectrogram\n","    audio = load_audio(audio)\n","  File \"/usr/local/lib/python3.10/dist-packages/whisper/audio.py\", line 60, in load_audio\n","    raise RuntimeError(f\"Failed to load audio: {e.stderr.decode()}\") from e\n","RuntimeError: Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","/content/drive/MyDrive/졸프/ML/STT/sample/stt_test.wav: No such file or directory\n","\n","Skipping /content/drive/MyDrive/졸프/ML/STT/sample/stt_test.wav due to RuntimeError: Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n","  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n","  libavutil      56. 70.100 / 56. 70.100\n","  libavcodec     58.134.100 / 58.134.100\n","  libavformat    58. 76.100 / 58. 76.100\n","  libavdevice    58. 13.100 / 58. 13.100\n","  libavfilter     7.110.100 /  7.110.100\n","  libswscale      5.  9.100 /  5.  9.100\n","  libswresample   3.  9.100 /  3.  9.100\n","  libpostproc    55.  9.100 / 55.  9.100\n","/content/drive/MyDrive/졸프/ML/STT/sample/stt_test.wav: No such file or directory\n","\n"]}],"source":["!whisper /content/drive/MyDrive/leanai/ML/STT/sample/stt_test.wav --model large"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}